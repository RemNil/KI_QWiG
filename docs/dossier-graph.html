<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Dossier-Graph: Model Fine-Tuning for IQWiG Domain Knowledge | Dossier-Graph: A Knowledge Graph for German HTA reports</title>
  <meta name="description" content="Der Dossier-Graf." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Dossier-Graph: Model Fine-Tuning for IQWiG Domain Knowledge | Dossier-Graph: A Knowledge Graph for German HTA reports" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Der Dossier-Graf." />
  <meta name="github-repo" content="RemNil/remnil.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Dossier-Graph: Model Fine-Tuning for IQWiG Domain Knowledge | Dossier-Graph: A Knowledge Graph for German HTA reports" />
  
  <meta name="twitter:description" content="Der Dossier-Graf." />
  

<meta name="author" content="meRLin RemNil" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="concept-development-and-empirical-data.html"/>
<link rel="next" href="how-it-works-and-how-its-going.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/d3-3.5.3/d3.min.js"></script>
<link href="libs/colorbrewer-1/colorbrewer.css" rel="stylesheet" />
<script src="libs/colorbrewer-1/colorbrewer.js"></script>
<link href="libs/streamgraph-1/streamgraph.css" rel="stylesheet" />
<script src="libs/streamgraph-binding-0.9.0/streamgraph.js"></script>
<script async defer src="https://hypothes.is/embed.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="text-align:left;">
  <img src="images/D_GRAF.png" class="sidebar-logo">
</li>
<li><a href="./">Dossier-Graph</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Project summary</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#key-features"><i class="fa fa-check"></i>Key Features</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-it-matters"><i class="fa fa-check"></i>Why it matters</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#found-a-mistake"><i class="fa fa-check"></i>Found a mistake?</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="clinical-trial-portfolio-analysis.html"><a href="clinical-trial-portfolio-analysis.html"><i class="fa fa-check"></i><b>2</b> Clinical Trial Portfolio Analysis</a>
<ul>
<li class="chapter" data-level="2.1" data-path="clinical-trial-portfolio-analysis.html"><a href="clinical-trial-portfolio-analysis.html#trial-portfolios-and-research-trajectories"><i class="fa fa-check"></i><b>2.1</b> Trial Portfolios and Research Trajectories</a></li>
<li class="chapter" data-level="2.2" data-path="clinical-trial-portfolio-analysis.html"><a href="clinical-trial-portfolio-analysis.html#limitations-of-hitorical-data-analysis"><i class="fa fa-check"></i><b>2.2</b> Limitations of hitorical data analysis</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="knowledge-graph.html"><a href="knowledge-graph.html"><i class="fa fa-check"></i><b>3</b> Knowledge Graph</a>
<ul>
<li class="chapter" data-level="3.1" data-path="knowledge-graph.html"><a href="knowledge-graph.html#data-sources"><i class="fa fa-check"></i><b>3.1</b> Data sources</a></li>
<li class="chapter" data-level="3.2" data-path="knowledge-graph.html"><a href="knowledge-graph.html#data-processing"><i class="fa fa-check"></i><b>3.2</b> Data processing</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="knowledge-graph.html"><a href="knowledge-graph.html#metadata-extraction"><i class="fa fa-check"></i><b>3.2.1</b> Metadata Extraction</a></li>
<li class="chapter" data-level="3.2.2" data-path="knowledge-graph.html"><a href="knowledge-graph.html#concept-annotation"><i class="fa fa-check"></i><b>3.2.2</b> Concept Annotation</a></li>
<li class="chapter" data-level="3.2.3" data-path="knowledge-graph.html"><a href="knowledge-graph.html#abbreviation-list-extraction"><i class="fa fa-check"></i><b>3.2.3</b> Abbreviation List Extraction</a></li>
<li class="chapter" data-level="3.2.4" data-path="knowledge-graph.html"><a href="knowledge-graph.html#structural-hierarchy-preservation"><i class="fa fa-check"></i><b>3.2.4</b> Structural Hierarchy Preservation</a></li>
<li class="chapter" data-level="3.2.5" data-path="knowledge-graph.html"><a href="knowledge-graph.html#semantic-integration-of-tables-and-text"><i class="fa fa-check"></i><b>3.2.5</b> Semantic Integration of Tables and Text</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="knowledge-graph.html"><a href="knowledge-graph.html#graph-development"><i class="fa fa-check"></i><b>3.3</b> Graph development</a></li>
<li class="chapter" data-level="3.4" data-path="knowledge-graph.html"><a href="knowledge-graph.html#quality-assurance"><i class="fa fa-check"></i><b>3.4</b> Quality Assurance</a></li>
<li class="chapter" data-level="3.5" data-path="knowledge-graph.html"><a href="knowledge-graph.html#model-deployment"><i class="fa fa-check"></i><b>3.5</b> Model deployment</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="concept-development-and-empirical-data.html"><a href="concept-development-and-empirical-data.html"><i class="fa fa-check"></i><b>4</b> Concept development and empirical data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="concept-development-and-empirical-data.html"><a href="concept-development-and-empirical-data.html#rationale"><i class="fa fa-check"></i><b>4.1</b> Rationale</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dossier-graph.html"><a href="dossier-graph.html"><i class="fa fa-check"></i><b>5</b> Dossier-Graph: Model Fine-Tuning for IQWiG Domain Knowledge</a>
<ul>
<li class="chapter" data-level="5.1" data-path="dossier-graph.html"><a href="dossier-graph.html#overview"><i class="fa fa-check"></i><b>5.1</b> Overview</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="dossier-graph.html"><a href="dossier-graph.html#system-requirements"><i class="fa fa-check"></i><b>5.1.1</b> System Requirements</a></li>
<li class="chapter" data-level="5.1.2" data-path="dossier-graph.html"><a href="dossier-graph.html#core-capabilities"><i class="fa fa-check"></i><b>5.1.2</b> Core Capabilities</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="dossier-graph.html"><a href="dossier-graph.html#implementation-architecture"><i class="fa fa-check"></i><b>5.2</b> Implementation Architecture</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="dossier-graph.html"><a href="dossier-graph.html#technical-stack"><i class="fa fa-check"></i><b>5.2.1</b> Technical Stack</a></li>
<li class="chapter" data-level="5.2.2" data-path="dossier-graph.html"><a href="dossier-graph.html#lora-configuration"><i class="fa fa-check"></i><b>5.2.2</b> LoRA Configuration</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="dossier-graph.html"><a href="dossier-graph.html#data-preparation"><i class="fa fa-check"></i><b>5.3</b> Data Preparation Pipeline</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="dossier-graph.html"><a href="dossier-graph.html#document-processing"><i class="fa fa-check"></i><b>5.3.1</b> Step 1: Document Processing</a></li>
<li class="chapter" data-level="5.3.2" data-path="dossier-graph.html"><a href="dossier-graph.html#training-data-structure"><i class="fa fa-check"></i><b>5.3.2</b> Step 2: Training Data Structure</a></li>
<li class="chapter" data-level="5.3.3" data-path="dossier-graph.html"><a href="dossier-graph.html#data-requirements"><i class="fa fa-check"></i><b>5.3.3</b> Data Requirements</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="dossier-graph.html"><a href="dossier-graph.html#model-training"><i class="fa fa-check"></i><b>5.4</b> Model Training Process</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="dossier-graph.html"><a href="dossier-graph.html#environment-setup"><i class="fa fa-check"></i><b>5.4.1</b> Step 1: Environment Setup</a></li>
<li class="chapter" data-level="5.4.2" data-path="dossier-graph.html"><a href="dossier-graph.html#lora-application"><i class="fa fa-check"></i><b>5.4.2</b> Step 2: LoRA Application</a></li>
<li class="chapter" data-level="5.4.3" data-path="dossier-graph.html"><a href="dossier-graph.html#training-loop"><i class="fa fa-check"></i><b>5.4.3</b> Step 3: Training Loop</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="dossier-graph.html"><a href="dossier-graph.html#model-validation"><i class="fa fa-check"></i><b>5.5</b> Model Validation</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="dossier-graph.html"><a href="dossier-graph.html#evaluation-metrics"><i class="fa fa-check"></i><b>5.5.1</b> Evaluation Metrics</a></li>
<li class="chapter" data-level="5.5.2" data-path="dossier-graph.html"><a href="dossier-graph.html#validation-strategy"><i class="fa fa-check"></i><b>5.5.2</b> Validation Strategy</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="dossier-graph.html"><a href="dossier-graph.html#deployment"><i class="fa fa-check"></i><b>5.6</b> Deployment and Inference</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="dossier-graph.html"><a href="dossier-graph.html#model-usage"><i class="fa fa-check"></i><b>5.6.1</b> Model Usage</a></li>
<li class="chapter" data-level="5.6.2" data-path="dossier-graph.html"><a href="dossier-graph.html#example-applications"><i class="fa fa-check"></i><b>5.6.2</b> Example Applications</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="dossier-graph.html"><a href="dossier-graph.html#success-factors"><i class="fa fa-check"></i><b>5.7</b> Critical Success Factors</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="dossier-graph.html"><a href="dossier-graph.html#data-quality"><i class="fa fa-check"></i><b>5.7.1</b> Data Quality</a></li>
<li class="chapter" data-level="5.7.2" data-path="dossier-graph.html"><a href="dossier-graph.html#technical-considerations"><i class="fa fa-check"></i><b>5.7.2</b> Technical Considerations</a></li>
<li class="chapter" data-level="5.7.3" data-path="dossier-graph.html"><a href="dossier-graph.html#performance-optimization"><i class="fa fa-check"></i><b>5.7.3</b> Performance Optimization</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="dossier-graph.html"><a href="dossier-graph.html#mathematical-foundation"><i class="fa fa-check"></i><b>5.8</b> Mathematical Foundation</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="dossier-graph.html"><a href="dossier-graph.html#lora-mechanism"><i class="fa fa-check"></i><b>5.8.1</b> LoRA Mechanism</a></li>
<li class="chapter" data-level="5.8.2" data-path="dossier-graph.html"><a href="dossier-graph.html#training-objective"><i class="fa fa-check"></i><b>5.8.2</b> Training Objective</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="dossier-graph.html"><a href="dossier-graph.html#installation"><i class="fa fa-check"></i><b>5.9</b> Installation Guide</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="dossier-graph.html"><a href="dossier-graph.html#quick-start"><i class="fa fa-check"></i><b>5.9.1</b> Quick Start</a></li>
<li class="chapter" data-level="5.9.2" data-path="dossier-graph.html"><a href="dossier-graph.html#production-deployment"><i class="fa fa-check"></i><b>5.9.2</b> Production Deployment</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="dossier-graph.html"><a href="dossier-graph.html#troubleshooting"><i class="fa fa-check"></i><b>5.10</b> Troubleshooting</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="dossier-graph.html"><a href="dossier-graph.html#common-issues"><i class="fa fa-check"></i><b>5.10.1</b> Common Issues</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="dossier-graph.html"><a href="dossier-graph.html#conclusion"><i class="fa fa-check"></i><b>5.11</b> Conclusion</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="dossier-graph.html"><a href="dossier-graph.html#next-steps"><i class="fa fa-check"></i><b>5.11.1</b> Next Steps</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="dossier-graph.html"><a href="dossier-graph.html#references"><i class="fa fa-check"></i><b>5.12</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="how-it-works-and-how-its-going.html"><a href="how-it-works-and-how-its-going.html"><i class="fa fa-check"></i><b>6</b> How it works and how its going</a></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://remnil.github.io/" target=BIH QUEST Center</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Dossier-Graph: A Knowledge Graph for German HTA reports</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dossier-graph" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">5</span> Dossier-Graph: Model Fine-Tuning for IQWiG Domain Knowledge<a href="dossier-graph.html#dossier-graph" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="overview" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Overview<a href="dossier-graph.html#overview" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This guide provides comprehensive instructions for implementing the Dossier-Graph system, which creates a specialized AI assistant for Health Technology Assessment (HTA) tasks. The system fine-tunes large language models to understand and generate content following IQWiG (Institute for Quality and Efficiency in Health Care) standards.</p>
<div id="system-requirements" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> System Requirements<a href="dossier-graph.html#system-requirements" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Operating System</strong>: Ubuntu 24 LTS (recommended)</li>
<li><strong>Memory</strong>: Minimum 16GB RAM</li>
<li><strong>GPU</strong>: NVIDIA GPU with 8-12GB VRAM</li>
<li><strong>Storage</strong>: 50GB available space</li>
<li><strong>Python</strong>: Version 3.8 or higher</li>
</ul>
</div>
<div id="core-capabilities" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Core Capabilities<a href="dossier-graph.html#core-capabilities" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The fine-tuned model will be helpful in assisting to:</p>
<ul>
<li>Generate HTA summaries following IQWiG methodology standards</li>
<li>Evaluate evidence quality using IQWiG terminology</li>
<li>Draft benefit assessments with appropriate regulatory language</li>
<li>Analyze cost-effectiveness in accessible terms</li>
<li>Provide methodological guidance based on IQWiG precedents</li>
<li>Process both German and English HTA content</li>
</ul>
</div>
</div>
<div id="implementation-architecture" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Implementation Architecture<a href="dossier-graph.html#implementation-architecture" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="technical-stack" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Technical Stack<a href="dossier-graph.html#technical-stack" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Base Model</strong>: Mistral-7B-v0.1 (7 billion parameters)</li>
<li><strong>Fine-tuning Method</strong>: LoRA (Low-Rank Adaptation)</li>
<li><strong>Quantization</strong>: 4-bit precision for memory efficiency</li>
<li><strong>Framework</strong>: Hugging Face Transformers with PEFT</li>
</ul>
</div>
<div id="lora-configuration" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> LoRA Configuration<a href="dossier-graph.html#lora-configuration" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="dossier-graph.html#cb2-1" tabindex="-1"></a>target_modules <span class="op">=</span> [</span>
<span id="cb2-2"><a href="dossier-graph.html#cb2-2" tabindex="-1"></a>    <span class="st">&quot;q_proj&quot;</span>, <span class="st">&quot;k_proj&quot;</span>, <span class="st">&quot;v_proj&quot;</span>, <span class="st">&quot;o_proj&quot;</span>,  <span class="co"># Attention layers</span></span>
<span id="cb2-3"><a href="dossier-graph.html#cb2-3" tabindex="-1"></a>    <span class="st">&quot;gate_proj&quot;</span>, <span class="st">&quot;up_proj&quot;</span>, <span class="st">&quot;down_proj&quot;</span>,     <span class="co"># MLP layers  </span></span>
<span id="cb2-4"><a href="dossier-graph.html#cb2-4" tabindex="-1"></a>    <span class="st">&quot;lm_head&quot;</span>                                 <span class="co"># Output projection</span></span>
<span id="cb2-5"><a href="dossier-graph.html#cb2-5" tabindex="-1"></a>]</span>
<span id="cb2-6"><a href="dossier-graph.html#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="dossier-graph.html#cb2-7" tabindex="-1"></a>lora_config <span class="op">=</span> {</span>
<span id="cb2-8"><a href="dossier-graph.html#cb2-8" tabindex="-1"></a>    <span class="st">&quot;r&quot;</span>: <span class="dv">64</span>,                <span class="co"># Rank for medical terminology complexity</span></span>
<span id="cb2-9"><a href="dossier-graph.html#cb2-9" tabindex="-1"></a>    <span class="st">&quot;alpha&quot;</span>: <span class="dv">128</span>,           <span class="co"># 2x rank ratio for training stability</span></span>
<span id="cb2-10"><a href="dossier-graph.html#cb2-10" tabindex="-1"></a>    <span class="st">&quot;dropout&quot;</span>: <span class="fl">0.05</span>,        <span class="co"># Lower dropout for specialized domain</span></span>
<span id="cb2-11"><a href="dossier-graph.html#cb2-11" tabindex="-1"></a>    <span class="st">&quot;bias&quot;</span>: <span class="st">&quot;none&quot;</span>          <span class="co"># Standard for causal language models</span></span>
<span id="cb2-12"><a href="dossier-graph.html#cb2-12" tabindex="-1"></a>}</span></code></pre></div>
</div>
</div>
<div id="data-preparation" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Data Preparation Pipeline<a href="dossier-graph.html#data-preparation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="document-processing" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Step 1: Document Processing<a href="dossier-graph.html#document-processing" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Convert IQWiG reports into structured training data:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="dossier-graph.html#cb3-1" tabindex="-1"></a><span class="kw">def</span> process_hta_report(report_path):</span>
<span id="cb3-2"><a href="dossier-graph.html#cb3-2" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Extract and structure content from IQWiG reports.&quot;&quot;&quot;</span></span>
<span id="cb3-3"><a href="dossier-graph.html#cb3-3" tabindex="-1"></a>    </span>
<span id="cb3-4"><a href="dossier-graph.html#cb3-4" tabindex="-1"></a>    <span class="co"># Extract text from PDF</span></span>
<span id="cb3-5"><a href="dossier-graph.html#cb3-5" tabindex="-1"></a>    text_content <span class="op">=</span> extract_text_from_pdf(report_path)</span>
<span id="cb3-6"><a href="dossier-graph.html#cb3-6" tabindex="-1"></a>    </span>
<span id="cb3-7"><a href="dossier-graph.html#cb3-7" tabindex="-1"></a>    <span class="co"># Create instruction-based training examples</span></span>
<span id="cb3-8"><a href="dossier-graph.html#cb3-8" tabindex="-1"></a>    training_example <span class="op">=</span> {</span>
<span id="cb3-9"><a href="dossier-graph.html#cb3-9" tabindex="-1"></a>        <span class="st">&quot;instruction&quot;</span>: <span class="st">&quot;Summarize the benefit assessment findings&quot;</span>,</span>
<span id="cb3-10"><a href="dossier-graph.html#cb3-10" tabindex="-1"></a>        <span class="st">&quot;input&quot;</span>: <span class="ss">f&quot;IQWiG Report </span><span class="sc">{</span>report_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>text_content<span class="sc">}</span><span class="ss">&quot;</span>,</span>
<span id="cb3-11"><a href="dossier-graph.html#cb3-11" tabindex="-1"></a>        <span class="st">&quot;output&quot;</span>: <span class="st">&quot;The assessment concluded...&quot;</span></span>
<span id="cb3-12"><a href="dossier-graph.html#cb3-12" tabindex="-1"></a>    }</span>
<span id="cb3-13"><a href="dossier-graph.html#cb3-13" tabindex="-1"></a>    </span>
<span id="cb3-14"><a href="dossier-graph.html#cb3-14" tabindex="-1"></a>    <span class="cf">return</span> format_as_jsonl(training_example)</span></code></pre></div>
</div>
<div id="training-data-structure" class="section level3 hasAnchor" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Step 2: Training Data Structure<a href="dossier-graph.html#training-data-structure" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Each training example follows this JSONL format:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb4-1"><a href="dossier-graph.html#cb4-1" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb4-2"><a href="dossier-graph.html#cb4-2" tabindex="-1"></a>  <span class="dt">&quot;instruction&quot;</span><span class="fu">:</span> <span class="st">&quot;Evaluate the evidence quality for pembrolizumab in melanoma&quot;</span><span class="fu">,</span></span>
<span id="cb4-3"><a href="dossier-graph.html#cb4-3" tabindex="-1"></a>  <span class="dt">&quot;input&quot;</span><span class="fu">:</span> <span class="st">&quot;Single RCT, n=834 patients, 22-month follow-up, primary endpoint: PFS&quot;</span><span class="fu">,</span></span>
<span id="cb4-4"><a href="dossier-graph.html#cb4-4" tabindex="-1"></a>  <span class="dt">&quot;output&quot;</span><span class="fu">:</span> <span class="st">&quot;The evidence quality is rated as moderate (GRADE). While the single RCT provides robust data with adequate sample size and follow-up duration, the limitation to a single study reduces confidence in the generalizability of findings.&quot;</span></span>
<span id="cb4-5"><a href="dossier-graph.html#cb4-5" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
</div>
<div id="data-requirements" class="section level3 hasAnchor" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> Data Requirements<a href="dossier-graph.html#data-requirements" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr class="header">
<th align="left">Task Type</th>
<th align="left">Minimum Examples</th>
<th align="left">Recommended</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Evidence Assessment</td>
<td align="left">200</td>
<td align="left">500+</td>
</tr>
<tr class="even">
<td align="left">Benefit Rating</td>
<td align="left">200</td>
<td align="left">400+</td>
</tr>
<tr class="odd">
<td align="left">Cost-Effectiveness Analysis</td>
<td align="left">150</td>
<td align="left">300+</td>
</tr>
<tr class="even">
<td align="left">Methodology Evaluation</td>
<td align="left">100</td>
<td align="left">250+</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="model-training" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Model Training Process<a href="dossier-graph.html#model-training" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="environment-setup" class="section level3 hasAnchor" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Step 1: Environment Setup<a href="dossier-graph.html#environment-setup" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="dossier-graph.html#cb5-1" tabindex="-1"></a><span class="co"># Install required packages</span></span>
<span id="cb5-2"><a href="dossier-graph.html#cb5-2" tabindex="-1"></a><span class="ex">pip</span> install torch transformers peft trl datasets accelerate bitsandbytes</span>
<span id="cb5-3"><a href="dossier-graph.html#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="dossier-graph.html#cb5-4" tabindex="-1"></a><span class="co"># Load and compress base model</span></span>
<span id="cb5-5"><a href="dossier-graph.html#cb5-5" tabindex="-1"></a><span class="ex">from</span> transformers import AutoModelForCausalLM, BitsAndBytesConfig</span>
<span id="cb5-6"><a href="dossier-graph.html#cb5-6" tabindex="-1"></a></span>
<span id="cb5-7"><a href="dossier-graph.html#cb5-7" tabindex="-1"></a><span class="ex">quantization_config</span> = BitsAndBytesConfig<span class="er">(</span></span>
<span id="cb5-8"><a href="dossier-graph.html#cb5-8" tabindex="-1"></a>    <span class="va">load_in_4bit</span><span class="op">=</span>True,</span>
<span id="cb5-9"><a href="dossier-graph.html#cb5-9" tabindex="-1"></a>    <span class="va">bnb_4bit_compute_dtype</span><span class="op">=</span>torch.float16,</span>
<span id="cb5-10"><a href="dossier-graph.html#cb5-10" tabindex="-1"></a>    <span class="va">bnb_4bit_quant_type</span><span class="op">=</span><span class="st">&quot;nf4&quot;</span></span>
<span id="cb5-11"><a href="dossier-graph.html#cb5-11" tabindex="-1"></a><span class="kw">)</span></span>
<span id="cb5-12"><a href="dossier-graph.html#cb5-12" tabindex="-1"></a></span>
<span id="cb5-13"><a href="dossier-graph.html#cb5-13" tabindex="-1"></a><span class="ex">model</span> = AutoModelForCausalLM.from_pretrained<span class="er">(</span></span>
<span id="cb5-14"><a href="dossier-graph.html#cb5-14" tabindex="-1"></a>    <span class="st">&quot;mistralai/Mistral-7B-v0.1&quot;</span><span class="ex">,</span></span>
<span id="cb5-15"><a href="dossier-graph.html#cb5-15" tabindex="-1"></a>    <span class="va">quantization_config</span><span class="op">=</span>quantization_config,</span>
<span id="cb5-16"><a href="dossier-graph.html#cb5-16" tabindex="-1"></a>    <span class="va">device_map</span><span class="op">=</span><span class="st">&quot;auto&quot;</span></span>
<span id="cb5-17"><a href="dossier-graph.html#cb5-17" tabindex="-1"></a><span class="kw">)</span></span></code></pre></div>
</div>
<div id="lora-application" class="section level3 hasAnchor" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Step 2: LoRA Application<a href="dossier-graph.html#lora-application" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The LoRA method adds small, trainable matrices to specific model layers:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="dossier-graph.html#cb6-1" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> get_peft_model, LoraConfig</span>
<span id="cb6-2"><a href="dossier-graph.html#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="dossier-graph.html#cb6-3" tabindex="-1"></a>peft_config <span class="op">=</span> LoraConfig(</span>
<span id="cb6-4"><a href="dossier-graph.html#cb6-4" tabindex="-1"></a>    task_type<span class="op">=</span><span class="st">&quot;CAUSAL_LM&quot;</span>,</span>
<span id="cb6-5"><a href="dossier-graph.html#cb6-5" tabindex="-1"></a>    target_modules<span class="op">=</span>target_modules,</span>
<span id="cb6-6"><a href="dossier-graph.html#cb6-6" tabindex="-1"></a>    r<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb6-7"><a href="dossier-graph.html#cb6-7" tabindex="-1"></a>    lora_alpha<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb6-8"><a href="dossier-graph.html#cb6-8" tabindex="-1"></a>    lora_dropout<span class="op">=</span><span class="fl">0.05</span></span>
<span id="cb6-9"><a href="dossier-graph.html#cb6-9" tabindex="-1"></a>)</span>
<span id="cb6-10"><a href="dossier-graph.html#cb6-10" tabindex="-1"></a></span>
<span id="cb6-11"><a href="dossier-graph.html#cb6-11" tabindex="-1"></a>model <span class="op">=</span> get_peft_model(model, peft_config)</span>
<span id="cb6-12"><a href="dossier-graph.html#cb6-12" tabindex="-1"></a><span class="co"># Trainable parameters: ~0.3% of original model</span></span></code></pre></div>
</div>
<div id="training-loop" class="section level3 hasAnchor" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Step 3: Training Loop<a href="dossier-graph.html#training-loop" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="dossier-graph.html#cb7-1" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb7-2"><a href="dossier-graph.html#cb7-2" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-3"><a href="dossier-graph.html#cb7-3" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb7-4"><a href="dossier-graph.html#cb7-4" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb7-5"><a href="dossier-graph.html#cb7-5" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-4</span>,</span>
<span id="cb7-6"><a href="dossier-graph.html#cb7-6" tabindex="-1"></a>    warmup_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb7-7"><a href="dossier-graph.html#cb7-7" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">25</span>,</span>
<span id="cb7-8"><a href="dossier-graph.html#cb7-8" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">&quot;epoch&quot;</span>,</span>
<span id="cb7-9"><a href="dossier-graph.html#cb7-9" tabindex="-1"></a>    evaluation_strategy<span class="op">=</span><span class="st">&quot;steps&quot;</span>,</span>
<span id="cb7-10"><a href="dossier-graph.html#cb7-10" tabindex="-1"></a>    eval_steps<span class="op">=</span><span class="dv">100</span></span>
<span id="cb7-11"><a href="dossier-graph.html#cb7-11" tabindex="-1"></a>)</span>
<span id="cb7-12"><a href="dossier-graph.html#cb7-12" tabindex="-1"></a></span>
<span id="cb7-13"><a href="dossier-graph.html#cb7-13" tabindex="-1"></a>trainer <span class="op">=</span> SFTTrainer(</span>
<span id="cb7-14"><a href="dossier-graph.html#cb7-14" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb7-15"><a href="dossier-graph.html#cb7-15" tabindex="-1"></a>    train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb7-16"><a href="dossier-graph.html#cb7-16" tabindex="-1"></a>    eval_dataset<span class="op">=</span>eval_dataset,</span>
<span id="cb7-17"><a href="dossier-graph.html#cb7-17" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb7-18"><a href="dossier-graph.html#cb7-18" tabindex="-1"></a>    max_seq_length<span class="op">=</span><span class="dv">2048</span></span>
<span id="cb7-19"><a href="dossier-graph.html#cb7-19" tabindex="-1"></a>)</span>
<span id="cb7-20"><a href="dossier-graph.html#cb7-20" tabindex="-1"></a></span>
<span id="cb7-21"><a href="dossier-graph.html#cb7-21" tabindex="-1"></a>trainer.train()</span></code></pre></div>
</div>
</div>
<div id="model-validation" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Model Validation<a href="dossier-graph.html#model-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="evaluation-metrics" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Evaluation Metrics<a href="dossier-graph.html#evaluation-metrics" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="perplexity" class="section level4 hasAnchor" number="5.5.1.1">
<h4><span class="header-section-number">5.5.1.1</span> 1. <strong>Perplexity</strong><a href="dossier-graph.html#perplexity" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>What it measures</strong>: How “surprised” the model is by unseen HTA text - lower scores mean better prediction.</p>
<p><strong>Rationale</strong>: Perplexity quantifies whether the model has genuinely learned HTA language patterns. If a model achieves low perplexity on held-out IQWiG reports, it demonstrates it can predict the next word in HTA contexts accurately. For example, after “The evidence quality is rated as”, a well-trained model should predict “moderate” or “high” (low perplexity), not random medical terms (high perplexity).</p>
<p><strong>Why essential</strong>: It’s an objective, automated metric that catches overfitting - if perplexity is low on training data but high on validation data, the model memorized rather than learned.</p>
</div>
<div id="rouge-scores" class="section level4 hasAnchor" number="5.5.1.2">
<h4><span class="header-section-number">5.5.1.2</span> 2. <strong>ROUGE Scores</strong><a href="dossier-graph.html#rouge-scores" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>What it measures</strong>: Overlap between generated summaries and expert-written reference summaries (word/phrase matching).</p>
<p><strong>Rationale</strong>: HTA reports require precise summarization of complex evidence. ROUGE scores (Recall-Oriented Understudy for Gisting Evaluation) compare the model’s summaries against gold-standard IQWiG summaries, measuring whether key phrases like “considerable additional benefit” or “hint of lesser benefit” appear correctly. ROUGE-L specifically captures longest common sequences, ensuring the model maintains IQWiG’s logical flow.</p>
<p><strong>Why essential</strong>: Validates that the model can distill lengthy clinical evidence into concise, accurate assessments matching IQWiG’s standardized summary style.</p>
</div>
<div id="domain-specific-accuracy" class="section level4 hasAnchor" number="5.5.1.3">
<h4><span class="header-section-number">5.5.1.3</span> 3. <strong>Domain-Specific Accuracy</strong><a href="dossier-graph.html#domain-specific-accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>What it measures</strong>: Correct usage of IQWiG-specific terminology and methodological concepts.</p>
<p><strong>Rationale</strong>: IQWiG uses precise regulatory language with specific meanings. The model must distinguish between “proof” vs “indication” vs “hint” of benefit (Beleg/Hinweis/Anhaltspunkt in German), use GRADE terminology correctly, and apply the right benefit categories. This metric tests terminology on a curated test set - for instance, given specific evidence, does the model correctly classify it as “major” vs “considerable” additional benefit?</p>
<p><strong>Why essential</strong>: Generic medical language isn’t sufficient for regulatory submissions. Misusing terms like “significant benefit” instead of IQWiG’s exact categories could invalidate an assessment.</p>
</div>
<div id="human-expert-review" class="section level4 hasAnchor" number="5.5.1.4">
<h4><span class="header-section-number">5.5.1.4</span> 4. <strong>Human Expert Review</strong><a href="dossier-graph.html#human-expert-review" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>What it measures</strong>: Qualitative assessment of readability, logical coherence, and regulatory appropriateness.</p>
<p><strong>Rationale</strong>: Automated metrics miss critical nuances that HTA professionals immediately recognize. Experts evaluate whether the model’s outputs would be acceptable in actual IQWiG proceedings - checking for logical argumentation, appropriate hedging language, correct interpretation of statistical significance vs clinical relevance, and adherence to IQWiG’s methodological standards that aren’t captured by word matching.</p>
<p><strong>Why essential</strong>: The ultimate test is whether HTA professionals would trust and use the output. Expert review catches dangerous errors (like misinterpreting non-inferiority trials) that automated metrics might miss.</p>
</div>
<div id="combined-rationale" class="section level4 hasAnchor" number="5.5.1.5">
<h4><span class="header-section-number">5.5.1.5</span> Combined Rationale<a href="dossier-graph.html#combined-rationale" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>These four metrics create a comprehensive evaluation framework:
- <strong>Perplexity</strong> ensures fundamental language modeling capability
- <strong>ROUGE</strong> validates content accuracy and completeness<br />
- <strong>Domain Accuracy</strong> confirms regulatory compliance
- <strong>Expert Review</strong> provides the final quality gate</p>
<p>Together, they prevent deploying a model that seems statistically competent but fails in real HTA contexts - a critical safety requirement for regulatory healthcare applications.</p>
</div>
</div>
<div id="validation-strategy" class="section level3 hasAnchor" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Validation Strategy<a href="dossier-graph.html#validation-strategy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="dossier-graph.html#cb8-1" tabindex="-1"></a><span class="co"># Split data: 80% training, 20% validation</span></span>
<span id="cb8-2"><a href="dossier-graph.html#cb8-2" tabindex="-1"></a>train_reports <span class="op">=</span> reports[:<span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(reports))]</span>
<span id="cb8-3"><a href="dossier-graph.html#cb8-3" tabindex="-1"></a>val_reports <span class="op">=</span> reports[<span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(reports)):]</span>
<span id="cb8-4"><a href="dossier-graph.html#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="dossier-graph.html#cb8-5" tabindex="-1"></a><span class="co"># Test on unseen reports</span></span>
<span id="cb8-6"><a href="dossier-graph.html#cb8-6" tabindex="-1"></a>validation_results <span class="op">=</span> model.evaluate(val_reports)</span>
<span id="cb8-7"><a href="dossier-graph.html#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="dossier-graph.html#cb8-8" tabindex="-1"></a><span class="cf">if</span> validation_results[<span class="st">&#39;perplexity&#39;</span>] <span class="op">&gt;</span> threshold:</span>
<span id="cb8-9"><a href="dossier-graph.html#cb8-9" tabindex="-1"></a>    <span class="co"># Consider increasing training data or adjusting hyperparameters</span></span>
<span id="cb8-10"><a href="dossier-graph.html#cb8-10" tabindex="-1"></a>    optimize_training_parameters()</span></code></pre></div>
</div>
</div>
<div id="deployment" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Deployment and Inference<a href="dossier-graph.html#deployment" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="model-usage" class="section level3 hasAnchor" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Model Usage<a href="dossier-graph.html#model-usage" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="dossier-graph.html#cb9-1" tabindex="-1"></a><span class="kw">def</span> generate_hta_response(question, context):</span>
<span id="cb9-2"><a href="dossier-graph.html#cb9-2" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Generate HTA-compliant responses.&quot;&quot;&quot;</span></span>
<span id="cb9-3"><a href="dossier-graph.html#cb9-3" tabindex="-1"></a>    </span>
<span id="cb9-4"><a href="dossier-graph.html#cb9-4" tabindex="-1"></a>    <span class="co"># Format input following training schema</span></span>
<span id="cb9-5"><a href="dossier-graph.html#cb9-5" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f&quot;[INST] </span><span class="sc">{</span>question<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">Context: </span><span class="sc">{</span>context<span class="sc">}</span><span class="ss"> [/INST]&quot;</span></span>
<span id="cb9-6"><a href="dossier-graph.html#cb9-6" tabindex="-1"></a>    </span>
<span id="cb9-7"><a href="dossier-graph.html#cb9-7" tabindex="-1"></a>    <span class="co"># Tokenize and generate</span></span>
<span id="cb9-8"><a href="dossier-graph.html#cb9-8" tabindex="-1"></a>    inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">&quot;pt&quot;</span>)</span>
<span id="cb9-9"><a href="dossier-graph.html#cb9-9" tabindex="-1"></a>    outputs <span class="op">=</span> model.generate(</span>
<span id="cb9-10"><a href="dossier-graph.html#cb9-10" tabindex="-1"></a>        inputs.input_ids,</span>
<span id="cb9-11"><a href="dossier-graph.html#cb9-11" tabindex="-1"></a>        max_new_tokens<span class="op">=</span><span class="dv">512</span>,</span>
<span id="cb9-12"><a href="dossier-graph.html#cb9-12" tabindex="-1"></a>        temperature<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb9-13"><a href="dossier-graph.html#cb9-13" tabindex="-1"></a>        do_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-14"><a href="dossier-graph.html#cb9-14" tabindex="-1"></a>        top_p<span class="op">=</span><span class="fl">0.95</span></span>
<span id="cb9-15"><a href="dossier-graph.html#cb9-15" tabindex="-1"></a>    )</span>
<span id="cb9-16"><a href="dossier-graph.html#cb9-16" tabindex="-1"></a>    </span>
<span id="cb9-17"><a href="dossier-graph.html#cb9-17" tabindex="-1"></a>    <span class="cf">return</span> tokenizer.decode(outputs[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div id="example-applications" class="section level3 hasAnchor" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Example Applications<a href="dossier-graph.html#example-applications" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="dossier-graph.html#cb10-1" tabindex="-1"></a><span class="co"># Evidence quality assessment</span></span>
<span id="cb10-2"><a href="dossier-graph.html#cb10-2" tabindex="-1"></a>response <span class="op">=</span> generate_hta_response(</span>
<span id="cb10-3"><a href="dossier-graph.html#cb10-3" tabindex="-1"></a>    question<span class="op">=</span><span class="st">&quot;Assess the evidence quality for this intervention&quot;</span>,</span>
<span id="cb10-4"><a href="dossier-graph.html#cb10-4" tabindex="-1"></a>    context<span class="op">=</span><span class="st">&quot;Two RCTs (n=1,245 total), 12-month follow-up, consistent findings&quot;</span></span>
<span id="cb10-5"><a href="dossier-graph.html#cb10-5" tabindex="-1"></a>)</span>
<span id="cb10-6"><a href="dossier-graph.html#cb10-6" tabindex="-1"></a></span>
<span id="cb10-7"><a href="dossier-graph.html#cb10-7" tabindex="-1"></a><span class="co"># Benefit summary generation</span></span>
<span id="cb10-8"><a href="dossier-graph.html#cb10-8" tabindex="-1"></a>response <span class="op">=</span> generate_hta_response(</span>
<span id="cb10-9"><a href="dossier-graph.html#cb10-9" tabindex="-1"></a>    question<span class="op">=</span><span class="st">&quot;Summarize the additional benefit assessment&quot;</span>,</span>
<span id="cb10-10"><a href="dossier-graph.html#cb10-10" tabindex="-1"></a>    context<span class="op">=</span><span class="st">&quot;IQWiG Report A23-42: Primary endpoint met, QoL improved...&quot;</span></span>
<span id="cb10-11"><a href="dossier-graph.html#cb10-11" tabindex="-1"></a>)</span></code></pre></div>
</div>
</div>
<div id="success-factors" class="section level2 hasAnchor" number="5.7">
<h2><span class="header-section-number">5.7</span> Critical Success Factors<a href="dossier-graph.html#success-factors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-quality" class="section level3 hasAnchor" number="5.7.1">
<h3><span class="header-section-number">5.7.1</span> Data Quality<a href="dossier-graph.html#data-quality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Consistency</strong>: Ensure uniform terminology across training examples</li>
<li><strong>Completeness</strong>: Include all relevant IQWiG assessment types</li>
<li><strong>Accuracy</strong>: Verify expert annotations before training</li>
</ul>
</div>
<div id="technical-considerations" class="section level3 hasAnchor" number="5.7.2">
<h3><span class="header-section-number">5.7.2</span> Technical Considerations<a href="dossier-graph.html#technical-considerations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><strong>Memory Management</strong>: 4-bit quantization reduces VRAM from 28GB to 7GB</li>
<li><strong>Training Stability</strong>: Gradient accumulation enables larger effective batch sizes</li>
<li><strong>Overfitting Prevention</strong>: Regular validation on held-out reports</li>
</ol>
</div>
<div id="performance-optimization" class="section level3 hasAnchor" number="5.7.3">
<h3><span class="header-section-number">5.7.3</span> Performance Optimization<a href="dossier-graph.html#performance-optimization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<thead>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Impact</th>
<th align="left">Recommended Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Learning Rate</td>
<td align="left">Training stability</td>
<td align="left">2e-4 to 5e-4</td>
</tr>
<tr class="even">
<td align="left">LoRA Rank (r)</td>
<td align="left">Model capacity</td>
<td align="left">32-64 for medical domain</td>
</tr>
<tr class="odd">
<td align="left">Batch Size</td>
<td align="left">Memory usage</td>
<td align="left">4-8 with gradient accumulation</td>
</tr>
<tr class="even">
<td align="left">Training Epochs</td>
<td align="left">Model performance</td>
<td align="left">3-5 (monitor validation loss)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="mathematical-foundation" class="section level2 hasAnchor" number="5.8">
<h2><span class="header-section-number">5.8</span> Mathematical Foundation<a href="dossier-graph.html#mathematical-foundation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="lora-mechanism" class="section level3 hasAnchor" number="5.8.1">
<h3><span class="header-section-number">5.8.1</span> LoRA Mechanism<a href="dossier-graph.html#lora-mechanism" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Instead of updating all model parameters, LoRA introduces low-rank decomposition:</p>
<p><span class="math display">\[W_{new} = W_{original} + BA\]</span></p>
<p>Where:
- <span class="math inline">\(W_{original}\)</span> ∈ ℝ^{d×k} (frozen pre-trained weights)
- <span class="math inline">\(B\)</span> ∈ ℝ^{d×r} and <span class="math inline">\(A\)</span> ∈ ℝ^{r×k} (trainable matrices)
- <span class="math inline">\(r &lt;&lt; min(d, k)\)</span> (rank constraint)</p>
<p>This reduces trainable parameters from O(dk) to O(r(d+k)), typically a 99.7% reduction.</p>
</div>
<div id="training-objective" class="section level3 hasAnchor" number="5.8.2">
<h3><span class="header-section-number">5.8.2</span> Training Objective<a href="dossier-graph.html#training-objective" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The model optimizes cross-entropy loss over HTA-specific tokens:</p>
<p><span class="math display">\[L = -\sum_{i=1}^{N} \log P(y_i | x_{&lt;i}, \theta_{base} + \Delta\theta_{LoRA})\]</span></p>
<p>Where <span class="math inline">\(\Delta\theta_{LoRA}\)</span> represents the small parameter updates learned from IQWiG data.</p>
</div>
</div>
<div id="installation" class="section level2 hasAnchor" number="5.9">
<h2><span class="header-section-number">5.9</span> Installation Guide<a href="dossier-graph.html#installation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="quick-start" class="section level3 hasAnchor" number="5.9.1">
<h3><span class="header-section-number">5.9.1</span> Quick Start<a href="dossier-graph.html#quick-start" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Do not run: work in progress!</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb11-1"><a href="dossier-graph.html#cb11-1" tabindex="-1"></a><span class="co"># Clone repository</span></span>
<span id="cb11-2"><a href="dossier-graph.html#cb11-2" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/your-org/dossier-graph.git</span>
<span id="cb11-3"><a href="dossier-graph.html#cb11-3" tabindex="-1"></a><span class="bu">cd</span> dossier-graph</span>
<span id="cb11-4"><a href="dossier-graph.html#cb11-4" tabindex="-1"></a></span>
<span id="cb11-5"><a href="dossier-graph.html#cb11-5" tabindex="-1"></a><span class="co"># Create virtual environment</span></span>
<span id="cb11-6"><a href="dossier-graph.html#cb11-6" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> venv venv</span>
<span id="cb11-7"><a href="dossier-graph.html#cb11-7" tabindex="-1"></a><span class="bu">source</span> venv/bin/activate</span>
<span id="cb11-8"><a href="dossier-graph.html#cb11-8" tabindex="-1"></a></span>
<span id="cb11-9"><a href="dossier-graph.html#cb11-9" tabindex="-1"></a><span class="co"># Install dependencies</span></span>
<span id="cb11-10"><a href="dossier-graph.html#cb11-10" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-r</span> requirements.txt</span>
<span id="cb11-11"><a href="dossier-graph.html#cb11-11" tabindex="-1"></a></span>
<span id="cb11-12"><a href="dossier-graph.html#cb11-12" tabindex="-1"></a><span class="co"># Run training pipeline</span></span>
<span id="cb11-13"><a href="dossier-graph.html#cb11-13" tabindex="-1"></a><span class="ex">python</span> train_mistral_lora_hta.py <span class="dt">\</span></span>
<span id="cb11-14"><a href="dossier-graph.html#cb11-14" tabindex="-1"></a>    <span class="at">--data_path</span> ./data/iqwig_reports <span class="dt">\</span></span>
<span id="cb11-15"><a href="dossier-graph.html#cb11-15" tabindex="-1"></a>    <span class="at">--output_dir</span> ./models/hta_mistral <span class="dt">\</span></span>
<span id="cb11-16"><a href="dossier-graph.html#cb11-16" tabindex="-1"></a>    <span class="at">--num_epochs</span> 3</span></code></pre></div>
</div>
<div id="production-deployment" class="section level3 hasAnchor" number="5.9.2">
<h3><span class="header-section-number">5.9.2</span> Production Deployment<a href="dossier-graph.html#production-deployment" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For production environments, consider:</p>
<ol style="list-style-type: decimal">
<li><strong>API Service</strong>: Deploy model behind REST API for scalability</li>
<li><strong>Batch Processing</strong>: Implement queue system for high-volume requests</li>
<li><strong>Monitoring</strong>: Track inference latency and model performance metrics</li>
<li><strong>Version Control</strong>: Maintain model versioning for reproducibility</li>
</ol>
</div>
</div>
<div id="troubleshooting" class="section level2 hasAnchor" number="5.10">
<h2><span class="header-section-number">5.10</span> Troubleshooting<a href="dossier-graph.html#troubleshooting" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="common-issues" class="section level3 hasAnchor" number="5.10.1">
<h3><span class="header-section-number">5.10.1</span> Common Issues<a href="dossier-graph.html#common-issues" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<colgroup>
<col width="29%" />
<col width="29%" />
<col width="41%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Issue</th>
<th align="left">Cause</th>
<th align="left">Solution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Out of Memory</td>
<td align="left">Large batch size</td>
<td align="left">Reduce batch size or increase gradient accumulation</td>
</tr>
<tr class="even">
<td align="left">Poor Performance</td>
<td align="left">Insufficient data</td>
<td align="left">Increase training examples or use data augmentation</td>
</tr>
<tr class="odd">
<td align="left">Overfitting</td>
<td align="left">Too many epochs</td>
<td align="left">Implement early stopping based on validation loss</td>
</tr>
<tr class="even">
<td align="left">Slow Training</td>
<td align="left">Inefficient settings</td>
<td align="left">Enable mixed precision training (fp16)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="conclusion" class="section level2 hasAnchor" number="5.11">
<h2><span class="header-section-number">5.11</span> Conclusion<a href="dossier-graph.html#conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The Dossier-Graph system enables organizations to create specialized AI assistants that understand and generate HTA content following IQWiG standards. By leveraging LoRA fine-tuning on carefully curated datasets, the system achieves domain expertise while maintaining computational efficiency.</p>
<div id="next-steps" class="section level3 hasAnchor" number="5.11.1">
<h3><span class="header-section-number">5.11.1</span> Next Steps<a href="dossier-graph.html#next-steps" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Collect and prepare IQWiG reports for training</li>
<li>Set up development environment following this guide</li>
<li>Train initial model and evaluate performance</li>
<li>Iterate based on domain expert feedback</li>
<li>Deploy for production use</li>
</ol>
</div>
</div>
<div id="references" class="section level2 hasAnchor" number="5.12">
<h2><span class="header-section-number">5.12</span> References<a href="dossier-graph.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Hu, E. J., et al. (2021). LoRA: Low-Rank Adaptation of Large Language Models. arXiv:2106.09685</li>
<li>IQWiG Methods Papers and Guidelines: www.iqwig.de</li>
<li>Hugging Face PEFT Documentation: <a href="https://huggingface.co/docs/peft" class="uri">https://huggingface.co/docs/peft</a></li>
</ul>

</div>
</div>
<div class = rmdreview>
<br><font size="2">This book is in <b><a href="http://www.openreviewtoolkit.org/">Open Review</a></b>. I want your feedback to make the book better for you and other readers. To add your annotation, <span style="background-color: #3297FD; color: white">select some text</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. To see the annotations of others, click the <i class="h-icon-chevron-left"></i> in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-215" aria-hidden="true"></i></font>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="concept-development-and-empirical-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="how-it-works-and-how-its-going.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": true,
    "twitter": true,
    "linkedin": true,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["twitter", "linkedin"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": null,
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["bookdown-start.pdf", "bookdown-start.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  },
  "logo": "images/logo.png",
  "toolbar": {
    "position": "fixed"
  },
  "keep_files": "images",
  "split_by": "rmd",
  "split_bib": true,
  "number_sections": true,
  "number_depth": 2
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
