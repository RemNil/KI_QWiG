[["index.html", "Dossier-Graph: A Knowledge Graph for German HTA reports Project summary", " Dossier-Graph: A Knowledge Graph for German HTA reports Merlin RemNil 16.07.2025 Project summary Dossier-Graph is an open-source and free knowledge graph system designed for research and education, built on public data from transparent health technology assessments (IQWiG 2023). Its mission: transform a vast archive of dossier evaluations into a live, searchable database using AI. Key Features Flexible, Traceable Linking: Connects dossiers, addenda, tables, sections, and more complex conceptual relationships. Ensures both human-readable and machine-consumable navigation paths. AI-Driven Search &amp; Analysis: Automates extraction, semantic search, and interactive analysis. Users ask questions in natural language and receive comprehensive, cross-document answers instantly. Why it matters Clinical development of new medicines differs from many business models because it relies critically on voluntary, even altruistic (Jansen 2009) research participation and hence on public trust. “Information gain per unit of accepted research burden” is a useful concept introduced to think about how regulatory oversight learns from past clinical R&amp;D efforts – a prerequisite of earning public trust. Information is gained not only from conducting clinical research but throughout the entire regulatory process, including post-marketing health technology assessment. Therefore, research responsibilities to maximize available information extend well beyond publishing study results. In this spirit, the Dossier-Graph knowledge graph is designed to transform post-marketing health technology assessment data into actionable insights, honoring the contributions of the many patients involved in the underlying research. By integrating state-of-the-art information technology throughout the drug development and regulatory lifecycle, this project advances the actionable use of critical research information. Found a mistake? Open peer-review is enabled in this project using hypothes.is. This allows sentence-by-sentence annotation from readers directly on this page. Please feel free to annotate. Both constructive and destructive criticism is highly welcome. References IQWiG. 2023. “Allgemeine Methoden; Version 7.0.” [online] Zugriff: 02.07.2025. https://www.iqwig.de/methoden/allgemeine-methoden_version-7-0.pdf. Jansen, Lynn A. 2009. “The Ethics of Altruism in Clinical Research.” Hastings Center Report 39 (4): 26–36. "],["introduction.html", "1 Introduction", " 1 Introduction What if we could see the research landscape not as scattered trials, but as a living map of inquiry—constantly evolving, purposefully connected, and ethically aligned? With an AI-powered knowledge graph trained on the vast archive of HTA reports, could we finally chart clinical studies in real time, uncovering how each trial fits into the bigger picture—and whether it truly earns the burden it places on participants? "],["clinical-trial-portfolio-analysis.html", "2 Clinical Trial Portfolio Analysis 2.1 Trial Portfolios and Research Trajectories 2.2 Limitations of hitorical data analysis", " 2 Clinical Trial Portfolio Analysis Ethical justification for the burdens placed on clinical research participants extends well beyond rigorous trial design. Modern scholarship stresses that trials should form part of an aligned research portfolio, where each study fills knowledge gaps and builds on prior evidence, contributing to a coherent, cumulative understanding of therapeutic questions. This portfolio approach is central for generating social value and ethically justifying participant burdens, as research efforts that are strategically linked offer a far greater return on participant contribution than isolated studies (London and Kimmelman 2019; Kimmelman, Carlisle, and Gönen 2017; Kimmelman and London 2015). Evaluating clinical research from a bird’s eye perspective, particularly after drug approval, produces two key benefits: Improving Future Trials: Analyses of existing research portfolios can highlight recurring challenges or risks; these insights directly inform the design, oversight, and safety of subsequent studies. For example, patterns identified at the portfolio level can help investigators anticipate methodological pitfalls or ethical concerns (Bittlinger, Peppercorn, and Kimmelman 2022). Revealing Research Gaps: Only by viewing groups of related trials together do unmet needs and new research questions rise to the surface—questions invisible to single-study analysis, but crucial for continuous improvement and targeted innovation (Kimmelman, Carlisle, and Gönen 2017; London and Kimmelman 2019). 1. Contextualizing Research Within the Scientific Continuum Interdependence of Questions: Each study should not exist in isolation. Instead, it should build upon previous findings and lay the groundwork for subsequent inquiry. This continuity ensures that research is not a series of disconnected efforts, but a tapestry of knowledge where each thread informs and supports the others. Cumulative Value of Evidence: The justification for involving participants must consider how the current research contributes to a growing body of evidence. Studies should be positioned to fill genuine knowledge gaps, refine existing understanding, or resolve uncertainties left by prior trials. 2. Strategic Question Selection and Research Prioritization Meaningful Sequencing: What we choose to ask next matters. The process of formulating research questions must be deliberate, ensuring they are timely, necessary, and logically connected to what has been already established. This sequencing maximizes the efficiency and impact of participant commitments. Avoiding Redundancy and Waste: By coordinating research agendas and sharing data openly, the field can prevent unnecessary replication and avoid subjecting participants to studies of limited incremental value. 3. Ethical Stewardship: Participant Burden in Perspective Value Amplification: When research questions are interconnected and aligned towards elucidating a coherent “bigger picture,” the societal value gained for each participant’s sacrifice increases. Their contributions are part of a collective effort, not a solitary, potentially obscure, experiment. Transparency and Trust: Clearly articulating how each study fits within the broader research mission fosters public trust, honors participant altruism, and reinforces the legitimacy of the research burden. 4. Cultivating a Healthy Research Culture Interdisciplinary Collaboration: Encouraging collaboration across disciplines and institutions ensures that research priorities are shaped by a diversity of perspectives and pressing clinical realities. Vision and Foresight: Healthy research ecosystems invest in horizon scanning—anticipating future questions and challenges—to guide present study designs and ethical considerations. 2.1 Trial Portfolios and Research Trajectories Let us examine some examples using EMA data from the EMA website. On the x-axis we plot time (years) and on the y-axis we plot the “volume” (counts) of EMA approvals per category (therapeutic areas). We do so using a stream graph (Byron and Wattenberg 2008), where the volume of individual streams (i.e. number of approvals per year and therapeutic area) is proportional to the values in each category. div.blue { background-color: #e6f0ff; border-radius: 5px; padding: 20px; margin-bottom: 10px; /* adds vertical space below the box */ } Key features of stream graphs Trends Over Time: Easily see rises and falls in activity for different categories (e.g., trial phases, therapeutic areas). Relative Volumes: The thickness of each stream at a given time denotes the volume (number of trials or approvals) for that category. Research Shifts: Highlight when attention moves from one research area to another, or when new categories emerge. It’s particularly powerful for showing the temporal development of research portfolios, such as how the number of clinical trials in different indications expand, contract, or shift across years. This plot visually presents “trends” in approval rate per therapeutic area over time. The width of each category’s stream fluctuates, letting us spot certain observations (e.g., surges in lung cancer trials after pembrolizumab’s first lung approval). Events like regulatory approvals or new indication launches appear as “bursts.” Declining or “sunset” indications shrink and eventually disappear, providing a living map of the research focus over time as described in the reference example This streamgraph visualizes trends in EMA regulatory approval categories from the early 2000s to 2024. Each colored stream represents one category, with the stream’s thickness indicating the number of medicines approved under that category each year. Interpretation by Category: Additional monitoring (largest stream): This category has grown substantially since 2012, peaking in 2022. It reflects increased post-market surveillance requirements for newer medicines, possibly due to evolving safety monitoring standards. Generic or hybrid: Steady presence over the years, with moderate peaks around 2009–2012 and a strong resurgence from 2021–2024. This suggests growing availability and approval of off-patent medicines or new combinations/formulations. Orphan medicine: Consistent upward trend, especially post-2018, reflecting EMA’s ongoing support for therapies targeting rare diseases. Biosimilar: Emerging around 2010 and slowly gaining momentum. The rise in recent years aligns with the expiration of patents on major biologics. Accelerated assessment, Advanced therapy, Conditional approval, PRIME: priority medicine: These smaller streams show limited but increasing use, indicating selective but strategic application of fast-track or specialized pathways for innovative or high-need treatments. In sum, the graph shows that regulatory pathways tailored for innovation, safety, and patient access have become more prominent. Particularly, Additional monitoring and Orphan medicine categories have seen major growth, while generics and biosimilars reflect market maturity and cost-containment policies. Applications div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;} Portfolio Review: See if resources align with evolving scientific opportunities. Ethical Justification: Ensure new studies fill real knowledge gaps (not redundant with past research). Gap Analysis: Identify under-studied areas or indications ripe for new trials. 2.2 Limitations of hitorical data analysis Data Relevance and Timeliness: Historical data may not reflect recent changes in the environment, such as technological advancements, market disruptions, or shifts in consumer behavior. This can make insights obsolete or misleading. Quality and Completeness Issues: Historical datasets can suffer from inaccuracies, incompleteness, or inconsistent formats, reducing the reliability of any conclusions drawn. Survivorship Bias: The data might be affected by biases, such as focusing on entities that have survived or succeeded while ignoring those that have failed, leading to skewed interpretations (also known as survivorship bias). Limited Predictive Power: Historical patterns do not always guarantee future outcomes, especially in volatile environments or during unprecedented events. Unexpected disruptions (like the COVID-19 pandemic) often break with historical trends. Overfitting: There is a risk of creating models that fit historical data too closely but fail to generalize accurately to new situations or data—a problem especially in complex statistical modeling. Stifling Innovation: Exclusive reliance on past data can limit creativity, making organizations less likely to explore new approaches or adapt to novel circumstances. Cultural and Contextual Shifts: Societal, regulatory, or industry-specific changes can render historical data less useful for contemporary analysis, potentially leading to misaligned strategies References Bittlinger, Merlin, Jeffrey Peppercorn, and Jonathan Kimmelman. 2022. “Ethical Considerations for Phase I Trials in Oncology.” Journal of Clinical Oncology 40 (30): 3474–88. https://doi.org/10.1200/JCO.22.01123. Byron, Lee, and Martin Wattenberg. 2008. “Stacked Graphs–Geometry &amp; Aesthetics.” IEEE Transactions on Visualization and Computer Graphics 14 (6): 1245–52. Kimmelman, Jonathan, Benjamin Carlisle, and Mithat Gönen. 2017. “Drug Development at the Portfolio Level Is Important for Policy, Care Decisions and Human Protections.” Jama 318 (11): 1003–4. Kimmelman, Jonathan, and Alex John London. 2015. “The Structure of Clinical Translation: Efficiency, Information, and Ethics.” Hastings Center Report 45 (2): 27–39. London, Alex John, and Jonathan Kimmelman. 2019. “Clinical Trial Portfolios: A Critical Oversight in Human Research Ethics, Drug Regulation, and Policy.” Hastings Center Report 49 (4): 31–41. "],["how-it-works-and-how-its-going.html", "3 How it works and how its going", " 3 How it works and how its going Veritas filia temporis. div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;} This is my first conclusion This is my second conclusion Useful tools clinical trials viewer "],["references.html", "References", " References … you missed it. Please go back and click on some of the links for further reading… Bittlinger, Merlin, Jeffrey Peppercorn, and Jonathan Kimmelman. 2022. “Ethical Considerations for Phase I Trials in Oncology.” Journal of Clinical Oncology 40 (30): 3474–88. https://doi.org/10.1200/JCO.22.01123. Byron, Lee, and Martin Wattenberg. 2008. “Stacked Graphs–Geometry &amp; Aesthetics.” IEEE Transactions on Visualization and Computer Graphics 14 (6): 1245–52. IQWiG. 2023. “Allgemeine Methoden; Version 7.0.” [online] Zugriff: 02.07.2025. https://www.iqwig.de/methoden/allgemeine-methoden_version-7-0.pdf. Jansen, Lynn A. 2009. “The Ethics of Altruism in Clinical Research.” Hastings Center Report 39 (4): 26–36. Kimmelman, Jonathan, Benjamin Carlisle, and Mithat Gönen. 2017. “Drug Development at the Portfolio Level Is Important for Policy, Care Decisions and Human Protections.” Jama 318 (11): 1003–4. Kimmelman, Jonathan, and Alex John London. 2015. “The Structure of Clinical Translation: Efficiency, Information, and Ethics.” Hastings Center Report 45 (2): 27–39. London, Alex John, and Jonathan Kimmelman. 2019. “Clinical Trial Portfolios: A Critical Oversight in Human Research Ethics, Drug Regulation, and Policy.” Hastings Center Report 49 (4): 31–41. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
