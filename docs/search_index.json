[["index.html", "Dossier-Graph: A Knowledge Graph for German HTA reports Project summary", " Dossier-Graph: A Knowledge Graph for German HTA reports Merlin RemNil 15.07.2025 Project summary Dossier-Graph is an open-source and free knowledge graph system designed for research and education, built on public data from transparent health technology assessments (IQWiG 2023). Its mission: transform a vast archive of dossier evaluations into a live, searchable database using AI. Key Features Flexible, Traceable Linking: Connects dossiers, addenda, tables, sections, and more complex conceptual relationships. Ensures both human-readable and machine-consumable navigation paths. AI-Driven Search &amp; Analysis: Automates extraction, semantic search, and interactive analysis. Users ask questions in natural language and receive comprehensive, cross-document answers instantly. Why it matters Clinical development of new medicines differs from many business models because it relies critically on voluntary, even altruistic (Jansen 2009) research participation and hence on public trust. “Information gain per unit of accepted research burden” is a useful concept introduced to think about how regulatory oversight learns from past clinical R&amp;D efforts – a prerequisite of earning public trust. Information is gained not only from conducting clinical research but throughout the entire regulatory process, including post-marketing health technology assessment. Therefore, research responsibilities to maximize available information extend well beyond publishing study results. In this spirit, the Dossier-Graph knowledge graph is designed to transform post-marketing health technology assessment data into actionable insights, honoring the contributions of the many patients involved in the underlying research. By integrating state-of-the-art information technology throughout the drug development and regulatory lifecycle, this project advances the actionable use of critical research information. Found a mistake? Open peer-review is enabled in this project using hypothes.is. This allows sentence-by-sentence annotation from readers directly on this page. Please feel free to annotate. Both constructive and destructive criticism is highly welcome. References IQWiG. 2023. “Allgemeine Methoden; Version 7.0.” [online] Zugriff: 02.07.2025. https://www.iqwig.de/methoden/allgemeine-methoden_version-7-0.pdf. Jansen, Lynn A. 2009. “The Ethics of Altruism in Clinical Research.” Hastings Center Report 39 (4): 26–36. "],["introduction.html", "1 Introduction Research Portfolios: Cohesive and Purposeful Clinical Research Trial Portfolios", " 1 Introduction Research Portfolios: Cohesive and Purposeful Clinical Research Ethical justification for the burdens placed on clinical research participants extends well beyond rigorous trial design. Modern scholarship stresses that trials should form part of an aligned research portfolio, where each study fills knowledge gaps and builds on prior evidence, contributing to a coherent, cumulative understanding of therapeutic questions. This portfolio approach is central for generating social value and ethically justifying participant burdens, as research efforts that are strategically linked offer a far greater return on participant contribution than isolated studies (London and Kimmelman 2019; Kimmelman, Carlisle, and Gönen 2017; Kimmelman and London 2015). Evaluating clinical research from a bird’s eye perspective, particularly after drug approval, produces two key benefits: Improving Future Trials: Analyses of existing research portfolios can highlight recurring challenges or risks; these insights directly inform the design, oversight, and safety of subsequent studies. For example, patterns identified at the portfolio level can help investigators anticipate methodological pitfalls or ethical concerns (BittlingerPeppercornKimmelman2022?). Revealing Research Gaps: Only by viewing groups of related trials together do unmet needs and new research questions rise to the surface—questions invisible to single-study analysis, but crucial for continuous improvement and targeted innovation (Kimmelman, Carlisle, and Gönen 2017; London and Kimmelman 2019). 1. Contextualizing Research Within the Scientific Continuum Interdependence of Questions: Each study should not exist in isolation. Instead, it should build upon previous findings and lay the groundwork for subsequent inquiry. This continuity ensures that research is not a series of disconnected efforts, but a tapestry of knowledge where each thread informs and supports the others. Cumulative Value of Evidence: The justification for involving participants must consider how the current research contributes to a growing body of evidence. Studies should be positioned to fill genuine knowledge gaps, refine existing understanding, or resolve uncertainties left by prior trials. 2. Strategic Question Selection and Research Prioritization Meaningful Sequencing: What we choose to ask next matters. The process of formulating research questions must be deliberate, ensuring they are timely, necessary, and logically connected to what has been already established. This sequencing maximizes the efficiency and impact of participant commitments. Avoiding Redundancy and Waste: By coordinating research agendas and sharing data openly, the field can prevent unnecessary replication and avoid subjecting participants to studies of limited incremental value. 3. Ethical Stewardship: Participant Burden in Perspective Value Amplification: When research questions are interconnected and aligned towards elucidating a coherent “bigger picture,” the societal value gained for each participant’s sacrifice increases. Their contributions are part of a collective effort, not a solitary, potentially obscure, experiment. Transparency and Trust: Clearly articulating how each study fits within the broader research mission fosters public trust, honors participant altruism, and reinforces the legitimacy of the research burden. 4. Cultivating a Healthy Research Culture Interdisciplinary Collaboration: Encouraging collaboration across disciplines and institutions ensures that research priorities are shaped by a diversity of perspectives and pressing clinical realities. Vision and Foresight: Healthy research ecosystems invest in horizon scanning—anticipating future questions and challenges—to guide present study designs and ethical considerations. What if we could see the research landscape not as scattered trials, but as a living map of inquiry—constantly evolving, purposefully connected, and ethically aligned? With an AI-powered knowledge graph trained on the vast archive of HTA reports, could we finally chart clinical studies in real time, uncovering how each trial fits into the bigger picture—and whether it truly earns the burden it places on participants? Trial Portfolios text Dummy example is shown below: In such a Stream Graph (Byron and Wattenberg 2008), the volume of individual streams is proportional to the values in each category (i.e. number of approvals per year and therapeutic area). This plot is useful to quickly assess “trends” in approval rate per therapeutic area over time. For instance, if you hover over the graph, you will quickly discover that there were quite disproportionately many approvals for Arthritis lately. Shown are therapeutic indications mentioned in EPARS (Papathanasiou et al. 2016). Data freeze: 25. November 2019. Now imagine, we had retrospective access to the clinical trial application packages. 1.0.0.1 Useful tools clinical trials viewer References Byron, Lee, and Martin Wattenberg. 2008. “Stacked Graphs–Geometry &amp; Aesthetics.” IEEE Transactions on Visualization and Computer Graphics 14 (6): 1245–52. Kimmelman, Jonathan, Benjamin Carlisle, and Mithat Gönen. 2017. “Drug Development at the Portfolio Level Is Important for Policy, Care Decisions and Human Protections.” Jama 318 (11): 1003–4. Kimmelman, Jonathan, and Alex John London. 2015. “The Structure of Clinical Translation: Efficiency, Information, and Ethics.” Hastings Center Report 45 (2): 27–39. London, Alex John, and Jonathan Kimmelman. 2019. “Clinical Trial Portfolios: A Critical Oversight in Human Research Ethics, Drug Regulation, and Policy.” Hastings Center Report 49 (4): 31–41. Papathanasiou, Peter, Laurent Brassart, Paul Blake, Anna Hart, Lel Whitbread, Richard Pembrey, and Jill Kieffer. 2016. “Transparency in Drug Regulation: Public Assessment Reports in Europe and Australia.” Drug Discovery Today 21 (11): 1806–13. "],["how-it-works-and-how-its-going.html", "2 How it works and how its going", " 2 How it works and how its going Veritas filia temporis. div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;} This is my first conclusion This is my second conclusion "],["references.html", "References", " References … you missed it. Please go back and click on some of the links for further reading… Byron, Lee, and Martin Wattenberg. 2008. “Stacked Graphs–Geometry &amp; Aesthetics.” IEEE Transactions on Visualization and Computer Graphics 14 (6): 1245–52. IQWiG. 2023. “Allgemeine Methoden; Version 7.0.” [online] Zugriff: 02.07.2025. https://www.iqwig.de/methoden/allgemeine-methoden_version-7-0.pdf. Jansen, Lynn A. 2009. “The Ethics of Altruism in Clinical Research.” Hastings Center Report 39 (4): 26–36. Kimmelman, Jonathan, Benjamin Carlisle, and Mithat Gönen. 2017. “Drug Development at the Portfolio Level Is Important for Policy, Care Decisions and Human Protections.” Jama 318 (11): 1003–4. Kimmelman, Jonathan, and Alex John London. 2015. “The Structure of Clinical Translation: Efficiency, Information, and Ethics.” Hastings Center Report 45 (2): 27–39. London, Alex John, and Jonathan Kimmelman. 2019. “Clinical Trial Portfolios: A Critical Oversight in Human Research Ethics, Drug Regulation, and Policy.” Hastings Center Report 49 (4): 31–41. Papathanasiou, Peter, Laurent Brassart, Paul Blake, Anna Hart, Lel Whitbread, Richard Pembrey, and Jill Kieffer. 2016. “Transparency in Drug Regulation: Public Assessment Reports in Europe and Australia.” Drug Discovery Today 21 (11): 1806–13. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
